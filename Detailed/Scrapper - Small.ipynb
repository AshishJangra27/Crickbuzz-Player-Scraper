{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a65a9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dea045",
   "metadata": {},
   "source": [
    "### 1. Scraping Teams Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054f0d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teams.csv is created!\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "soup = BeautifulSoup(requests.get('https://www.cricbuzz.com/cricket-team').content,'html.parser')\n",
    "\n",
    "# Data of all the  Teams\n",
    "sp = soup.find('div', class_ = 'cb-col cb-col-100')                                       \n",
    "\n",
    "# Data of Each Team displayed at Left\n",
    "for team_data in sp.find_all('div', class_ = 'cb-col cb-col-50 cb-team-item cb-lst-itm cb-team-lft-item'):   \n",
    "    team_name = team_data.text.strip()\n",
    "    team_link = 'https://www.cricbuzz.com' + team_data.find('a').get('href') + '/players'\n",
    "    data.append([team_name, team_link])\n",
    "\n",
    "# Data of Each Team displayed at Right\n",
    "for team_data in sp.find_all('div', class_ = 'cb-col cb-col-50 cb-team-item cb-lst-itm cb-team-rght-item'):   \n",
    "    team_name = team_data.text.strip()\n",
    "    team_link = 'https://www.cricbuzz.com' + team_data.find('a').get('href') + '/players'\n",
    "    data.append([team_name, team_link])\n",
    "    \n",
    "df = pd.DataFrame(data, columns = ['name','link'])\n",
    "\n",
    "df.to_csv('teams.csv',index = False)\n",
    "print('teams.csv is created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a9c1c",
   "metadata": {},
   "source": [
    "### 2. Scraping Players Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357e8204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 37/37 [00:28<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "players.csv is created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "players_data = []\n",
    "\n",
    "for team_name, team_link in tqdm(data):           # Going through each team\n",
    "    soup = BeautifulSoup(requests.get(team_link).content, 'html.parser')\n",
    "    \n",
    "    for player in soup.find('div', class_ = 'cb-col-67 cb-col cb-left cb-top-zero').find_all('a'): # Players of Team\n",
    "        player_name = player.text.strip()\n",
    "        player_link = 'https://www.cricbuzz.com' + player.get('href').strip()\n",
    "        players_data.append([player_name, team_name, player_link])\n",
    "        \n",
    "        \n",
    "df = pd.DataFrame(players_data, columns = ['player','team','link'])\n",
    "df.to_csv('players.csv', index = False)\n",
    "print('players.csv is created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c223bfb",
   "metadata": {},
   "source": [
    "### 3. Scraping Players Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb6f569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 453/453 [08:05<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "final_data = []\n",
    "\n",
    "for name, team, link in tqdm(players_data):\n",
    "\n",
    "    details = []\n",
    "    \n",
    "    details.append(name)\n",
    "    details.append(team)\n",
    "    \n",
    "    soup = BeautifulSoup(requests.get(link).content,'html.parser')\n",
    "    \n",
    "    try:\n",
    "        # Basic Information\n",
    "        basic_info = [sp.text.strip() for sp in soup.find('div', class_ = 'cb-col cb-col-33 text-black').find_all('div', class_ = 'cb-col cb-col-60 cb-lst-itm-sm')[:3]]\n",
    "        details += basic_info\n",
    "\n",
    "\n",
    "        # Data of Height\n",
    "        height = soup.find('div', class_ = 'cb-col cb-col-33 text-black').find('div', class_ = 'cb-col cb-col-60').text.strip()\n",
    "        details.append(height)\n",
    "\n",
    "        # Ranks\n",
    "        ranks = [sp.text.strip() for sp in soup.find('div', class_ = 'cb-col cb-col-33 text-black').find_all('div', class_ = 'cb-col cb-col-25 cb-plyr-rank text-right')]\n",
    "        details += ranks\n",
    "\n",
    "\n",
    "        details.append(link)    \n",
    "        final_data.append(details)\n",
    "        \n",
    "    except:\n",
    "        details = []\n",
    "    \n",
    "df = pd.DataFrame(final_data, columns = ['name','team','date_of_birth','palce_of_birth','role','height',\n",
    "                                         'test_bat_rank','odi_bat_rank','t20_bat_rank',\n",
    "                                         'test_bow_rank','odi_bow_rank','t20_bow_rank',\n",
    "                                        'link'])\n",
    "\n",
    "df.to_csv('cricket.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17385724",
   "metadata": {},
   "source": [
    "### 4. Scraping Players Batting and Bawling history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c1b3d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 453/453 [06:42<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "links = list(pd.read_csv('cricket.csv')['link'].values)\n",
    "\n",
    "def get_col_names(table):                                     # Get Column Names from the Table\n",
    "    return [_.text.strip() for _ in table.find_all('th')]\n",
    "\n",
    "def get_data(table):                                          # Get Table Data\n",
    "    return [_.text.strip() for _ in table.find_all('td')]\n",
    "\n",
    "def get_rows(table):                                          # Get number of rows from the Table\n",
    "    return len(table.find('tbody').find_all('tr'))\n",
    "    \n",
    "def get_cols(table):                                          # Get number of columns from the Table\n",
    "    return len(get_col_names(table))\n",
    "\n",
    "def create_df(table):                                         # Create the DataFrame\n",
    "    data   = np.reshape(get_data(table), (get_rows(table), get_cols(table)))\n",
    "    return pd.DataFrame(data, columns = get_col_names(table))    \n",
    "\n",
    "bat_paths = []\n",
    "bow_paths = []\n",
    "\n",
    "\n",
    "for link in tqdm(links):                                  # Going through each player data one by one    \n",
    "    try:\n",
    "        soup = BeautifulSoup(requests.get(link).content,'lxml')\n",
    "\n",
    "        bat_table = soup.find_all('table', class_ = 'table cb-col-100 cb-plyr-thead')[0]\n",
    "        bow_table = soup.find_all('table', class_ = 'table cb-col-100 cb-plyr-thead')[1]\n",
    "\n",
    "        df_bat = create_df(bat_table)\n",
    "        df_bow = create_df(bow_table)\n",
    "\n",
    "        player_id = link.split('/')[-2]\n",
    "\n",
    "        bat_path = 'Scores/bat_' + player_id + '.csv'\n",
    "        bow_path = 'Scores/bow_' + player_id + '.csv'\n",
    "\n",
    "        df_bat.to_csv(bat_path, index = False)\n",
    "        df_bow.to_csv(bow_path, index = False)\n",
    "\n",
    "        bat_paths.append(bat_path)\n",
    "        bow_paths.append(bow_path)\n",
    "    \n",
    "    except:\n",
    "        bat_paths.append(np.nan)\n",
    "        bow_paths.append(np.nan)\n",
    "        \n",
    "        \n",
    "df = pd.read_csv('cricket.csv')\n",
    "\n",
    "df['bat_path'] = bat_paths\n",
    "df['bow_path'] = bow_paths\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df.to_csv('players_record.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6b22a",
   "metadata": {},
   "source": [
    "### 5. Merging the Records of Batting and Bawling Career of Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a74b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('players_record.csv')\n",
    "\n",
    "def get_cols(file_path, sep):  \n",
    "    cols = []\n",
    "    col_names = pd.read_csv(file_path).columns\n",
    "    for _ in ['Test','ODI','T20I','IPL']:\n",
    "        for col_name in col_names[1:]:\n",
    "            cols.append(sep + \"_\" + _ + \"_\" + col_name)\n",
    "    return cols\n",
    "\n",
    "def get_data(file_path, seq_len):\n",
    "    \n",
    "    df_ = pd.read_csv(file_path)\n",
    "\n",
    "    test = ['-' for i in range(seq_len)]\n",
    "    odi  = ['-' for i in range(seq_len)]\n",
    "    t20  = ['-' for i in range(seq_len)]\n",
    "    ipl  = ['-' for i in range(seq_len)]\n",
    "\n",
    "    for i in df_.values:   \n",
    "        if i[0] == 'Test':\n",
    "            test = i[1:]\n",
    "        if i[0] == 'ODI':\n",
    "            odi = i[1:]\n",
    "        if i[0] == 'T20I':\n",
    "            t20 = i[1:]\n",
    "        if i[0] == 'IPL':\n",
    "            ipl = i[1:]\n",
    "\n",
    "        final =  [_ for _ in test]\n",
    "        final += [_ for _ in odi ]\n",
    "        final += [_ for _ in t20 ]\n",
    "        final += [_ for _ in ipl ]\n",
    "    return final\n",
    "\n",
    "bat_data = []\n",
    "bow_data = []\n",
    "\n",
    "for i in df.values:\n",
    "    bat_path = i[-2]\n",
    "    bat_data.append(get_data(bat_path,13))\n",
    "    \n",
    "    bow_path = i[-1]\n",
    "    bow_data.append(get_data(bow_path,12))\n",
    "    \n",
    "    \n",
    "df_bat = pd.DataFrame(bat_data, columns = get_cols('Scores/bat_1413.csv', 'BT'))\n",
    "df_bat.to_csv('bat.csv', index = False)\n",
    "\n",
    "df_bow = pd.DataFrame(bow_data, columns = get_cols('Scores/bow_1413.csv', 'BW'))\n",
    "df_bow.to_csv('ball.csv', index = False)\n",
    "\n",
    "df_fin = pd.concat((df,df_bat,df_bow), axis = 1)\n",
    "df_fin.to_csv('final.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218d392",
   "metadata": {},
   "source": [
    "### 6. Creating Column Documentation JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da392d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = pd.read_csv('cricket.csv')['link'].values[0]\n",
    "soup = BeautifulSoup(requests.get(link).content,'lxml')\n",
    "\n",
    "batt_col = [[i.text,i.get('title')] for i in soup.find_all('table')[0].find_all('th')][1:]\n",
    "ball_col = [[i.text,i.get('title')] for i in soup.find_all('table')[1].find_all('th')][1:]\n",
    "\n",
    "dct = {}\n",
    "\n",
    "for i in batt_col:\n",
    "    for j in ['Test','ODI','T20I','IPL']:        \n",
    "        key = 'BT_' + j + '_' + i[0]\n",
    "        value = j + ' ' + i[1] + ' ' + 'as a battsman'\n",
    "        dct[key] = value\n",
    "for i in ball_col:\n",
    "    for j in ['Test','ODI','T20I','IPL']:        \n",
    "        key = 'BT_' + j + '_' + i[0]\n",
    "        value = j + ' ' + i[1] + ' ' + 'as a baller'\n",
    "        dct[key] = value\n",
    "\n",
    "        \n",
    "for i in  ['name','team',\n",
    "        'date_of_birth','palce_of_birth',\n",
    "        'role',    'height',\n",
    "        'test_bat_rank','odi_bat_rank','t20_bat_rank',\n",
    "        'test_bow_rank','odi_bow_rank',\n",
    "        't20_bow_rank','link', 'bat_path','bow_path']:\n",
    "\n",
    "    dct[i] = i + ' of the player'\n",
    "    \n",
    "fd = open('columns.json','w')\n",
    "fd.write(json.dumps(dct))\n",
    "fd.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
